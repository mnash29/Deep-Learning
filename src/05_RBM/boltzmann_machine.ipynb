{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/67_blog_image_2.png\" width=\"800\" height=\"500\">\n",
    "\n",
    "* Use-case: Recommender Systems\n",
    "* Undirected and Unsupervised models\n",
    "  * Generative deep-learning\n",
    "  * No output layer \n",
    "  * Each visible node is something that we measure, e.g. each component of a power plant\n",
    "  * Each hidden layer is something we don't measure, e.g. wind speed, humidity <img src=\"img/67_blog_image_3.png\" width=\"500\" height=\"250\" >\n",
    "* Energy-based models (EBM)\n",
    "  * Uses the Boltzmann distribution formula <img src=\"img/boltzmann_dist.png\" width=\"100\" height=\"50\" >\n",
    "  * Systems tend to move towards their lowest energy state\n",
    "  * [A Tutorial on Energy-Based Learning](http://yan.lecuncom/exdb/publis/pdf/lecun-06.pdf)\n",
    "  * Mr. Nobody\n",
    "* Restricted Boltzmann Machine (RBM) <img src=\"img/restricted_boltzmann_machine.png\" height=\"500\" width=\"800\" >\n",
    "  * In/visible nodes cannot connect to each other\n",
    "  * Visible nodes can be different movies\n",
    "  * Hidden nodes can be features such as movie genre, actor, award, director, etc.\n",
    "* Contrastive Divergence\n",
    "  * Allows RBM's to learn through Gibb's sampling\n",
    "  * Iteratively updates the weights to minimize the energy in the system\n",
    "  * [A Fast Learning Algorithm for Deep Belief Nets](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)\n",
    "* Deep Belief Networks (DBN)\n",
    "  * Stacked RBM's\n",
    "  * Greedy Layer-wise training\n",
    "  * Wake-Sleep algorithm\n",
    "  * Top two layers are undirected\n",
    "  * Bottom two layer connections flow downwards towards the inputs (directed)\n",
    "  * [Greedy Layer-Wise Training of Deep Networks](http://www.iro.umontreal.ca/~lisa/pointeurs/BengioNips2006all.pdf)\n",
    "* Deep Boltzmann Machines (DBM)\n",
    "  * Stacked RBM's but all connections remained undirected\n",
    "  * [Deep Boltzmann Machines](http://www.utstat.toronto.edu/~rsalakhu/dbm.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath, join, curdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import FloatTensor, mean, abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3883, 3), (6040, 5), (1000209, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "datapath = join(dirname(dirname(abspath(curdir))), \"data\", \"raw\", \"rbm\")\n",
    "\n",
    "movies = pd.read_csv(join(datapath, \"movielens-1m\", \"movies.dat\"),\n",
    "                     sep=\"::\",\n",
    "                     header=None,\n",
    "                     engine=\"python\",\n",
    "                     encoding=\"latin-1\")\n",
    "\n",
    "users = pd.read_csv(join(datapath, \"movielens-1m\", \"users.dat\"),\n",
    "                    sep=\"::\",\n",
    "                    header=None,\n",
    "                    engine=\"python\",\n",
    "                    encoding=\"latin-1\")\n",
    "\n",
    "ratings = pd.read_csv(join(datapath, \"movielens-1m\", \"ratings.dat\"),\n",
    "                      sep=\"::\",\n",
    "                      header=None,\n",
    "                      engine=\"python\",\n",
    "                      encoding=\"latin-1\")\n",
    "\n",
    "movies.shape, users.shape, ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 4), (20000, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare training and test sets\n",
    "train_df = pd.read_csv(join(datapath, \"movielens-100k\", \"u1.base\"),\n",
    "                        sep=\"\\t\",\n",
    "                        header=None)\n",
    "\n",
    "train_set = np.array(train_df, dtype=\"int\")\n",
    "\n",
    "test_df = pd.read_csv(join(datapath, \"movielens-100k\", \"u1.test\"),\n",
    "                        sep=\"\\t\",\n",
    "                        header=None)\n",
    "\n",
    "test_set = np.array(test_df, dtype=\"int\")\n",
    "\n",
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create matrices of total number of users and movies for bi-fold cross validation\n",
    "# The max user/movie ID may be present in the training or test data\n",
    "nb_users = int(max(max(train_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(train_set[:, 1]), max(test_set[:, 1])))\n",
    "\n",
    "nb_users, nb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data: np.ndarray) -> list:\n",
    "    \"\"\"Convert data into a matrix like structure.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "    data : np.ndarray\n",
    "        The data to transform\n",
    "    size : int\n",
    "        The total number of items in the overall dataset\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        The data transformed\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    for user_id in range(1, nb_users + 1):\n",
    "        # Get user movies and ratings\n",
    "        movie_ids = data[:, 1][data[:, 0] == user_id]\n",
    "        rating_ids = data[:, 2][data[:, 0] == user_id]\n",
    "\n",
    "        # Get all list of movie ratings by user, unrated movies = -1\n",
    "        ratings = -np.ones(nb_movies)\n",
    "        ratings[movie_ids - 1] = rating_ids # movie_ids starts at 1\n",
    "        new_data.append(np.array(ratings))\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 5.,  3.,  4., ..., -1., -1., -1.]),\n",
       " array([ 4., -1., -1., ..., -1., -1., -1.]),\n",
       " array([-1., -1., -1., ..., -1., -1., -1.]),\n",
       " array([-1., -1., -1., ..., -1., -1., -1.]),\n",
       " array([-1., -1., -1., ..., -1., -1., -1.])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_converted = convert(train_set)\n",
    "test_set_converted = convert(test_set)\n",
    "\n",
    "train_set_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1., -1., -1., ..., -1., -1., -1.]),\n",
       " array([-1., -1., -1., ..., -1., -1., -1.]),\n",
       " array([-1., -1., -1., ..., -1., -1., -1.]),\n",
       " array([-1., -1., -1., ..., -1., -1., -1.]),\n",
       " array([ 4.,  3., -1., ..., -1., -1., -1.])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/7z15rbls00b_kh6xj9_n97tr0000gp/T/ipykernel_52434/1494548815.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686209/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  train_set_ft = FloatTensor(train_set_converted)\n"
     ]
    }
   ],
   "source": [
    "# Convert data into tensors\n",
    "train_set_ft = FloatTensor(train_set_converted)\n",
    "test_set_ft = FloatTensor(test_set_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  3.,  4.,  ..., -1., -1., -1.],\n",
       "        [ 4., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_ft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [ 4.,  3., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_ft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ratings into binary (1=Liked, 0=Not Liked)\n",
    "train_set_ft[train_set_ft == 1] = 0\n",
    "train_set_ft[train_set_ft == 2] = 0\n",
    "train_set_ft[train_set_ft >= 3] = 1\n",
    "\n",
    "test_set_ft[test_set_ft == 1] = 0\n",
    "test_set_ft[test_set_ft == 2] = 0\n",
    "test_set_ft[test_set_ft >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_ft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [ 1.,  1., -1.,  ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_ft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbm import RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of visible nodes\n",
    "nv = len(train_set_ft[0])\n",
    "\n",
    "# Tuneable parameters, number of hidden nodes and number of batches per iteration\n",
    "nh = 150\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RBM model\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train_loss: 0.3574598729610443\n",
      "Epoch: 2 Train_loss: 0.25747954845428467\n",
      "Epoch: 3 Train_loss: 0.2497379034757614\n",
      "Epoch: 4 Train_loss: 0.25117620825767517\n",
      "Epoch: 5 Train_loss: 0.24890729784965515\n",
      "Epoch: 6 Train_loss: 0.24733179807662964\n",
      "Epoch: 7 Train_loss: 0.24786941707134247\n",
      "Epoch: 8 Train_loss: 0.25024890899658203\n",
      "Epoch: 9 Train_loss: 0.24323007464408875\n",
      "Epoch: 10 Train_loss: 0.24826949834823608\n"
     ]
    }
   ],
   "source": [
    "# Train the RBM model\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "\n",
    "    for uid in range(0, nb_users - batch_size, batch_size):\n",
    "        # Get initial visible nodes (movie ratings)\n",
    "        vk = train_set_ft[uid:uid+batch_size]\n",
    "        v0 = train_set_ft[uid:uid+batch_size]\n",
    "\n",
    "        # Get initial hidden node probabilities\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "\n",
    "        # contrastive divergence to obtain samples of\n",
    "        # the visible/hidden node activations after k-steps\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # Freeze visible nodes containing -1 ratings during training\n",
    "            # so we don't learn from movies that were not rated by the user\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "\n",
    "        # Get final hidden node probabilities after k-steps\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += mean(abs(v0[v0>=0] - vk[v0>=0]))\n",
    "\n",
    "        # RMSE Loss\n",
    "        # train_loss += np.sqrt(mean((v0[v0>=0] - vk[v0>=0])**2))\n",
    "\n",
    "        # Update counter to normalize train_loss\n",
    "        s += 1.\n",
    "\n",
    "    print(f\"Epoch: {epoch+1} Train_loss: {train_loss/s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Loss: 0.264729380607605\n"
     ]
    }
   ],
   "source": [
    "# Testing the RBM model\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "\n",
    "for uid in range(nb_users):\n",
    "    v = train_set_ft[uid:uid+1]\n",
    "    vt = test_set_ft[uid:uid+1]\n",
    "\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _, h = rbm.sample_h(v)\n",
    "        _, v = rbm.sample_v(h)\n",
    "\n",
    "        test_loss += mean(abs(vt[vt>=0] - v[vt>=0]))\n",
    "\n",
    "        # RMSE Loss\n",
    "        # test_loss += np.sqrt(mean((v0[v0>=0] - vk[v0>=0])**2))\n",
    "\n",
    "        s += 1.\n",
    "\n",
    "print(f\"Test_Loss: {test_loss/s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
